<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>DriveX</title>
    <meta name="author" content="  DriveX">
    <meta name="description" content="MetaDriverse for AI and Autonomy Research!
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">

    <!-- Chenda additional setting -->
    <link rel="stylesheet" id="elementor-frontend-css" href="https://template.makedreamwebsite.com/wp-content/plugins/elementor/assets/css/frontend-lite.min.css?ver=3.9.0" media="all">
    <link rel="stylesheet" id="elementor-post-1391-css" href="https://template.makedreamwebsite.com/wp-content/uploads/elementor/css/post-1391.css?ver=1670496920" media="all">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.1/css/all.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/fullPage.js/3.1.2/fullpage.min.css">
    <script src="https://unpkg.com/infinite-scroll@3/dist/infinite-scroll.pkgd.min.js"></script>
    <!-- Magnific Popup CSS and JS -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/magnific-popup.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/magnific-popup.js/1.1.0/jquery.magnific-popup.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css">
    <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
    <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">
    <link href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css" rel="stylesheet">
    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%9A%98%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://drivex.github.io//">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><img class="navbar-logo" src="/assets/img/DriveX/DriveX.png" alt="Project logo" style="height:80px; width:auto"></a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/"><span class="sr-only">(current)</span></a>
              </li>
              

              
              
                <li class="nav-item">
                  <a class="nav-link" href="#papers">Papers</a>
                </li>
              
                <li class="nav-item">
                  <a class="nav-link" href="#software">Software</a>
                </li>
              
                <li class="nav-item">
                  <a class="nav-link" href="#datasets">Datasets</a>
                </li>
              
                <li class="nav-item">
                  <a class="nav-link" href="#outreach">Outreach</a>
                </li>
              
                <li class="nav-item">
                  <a class="nav-link" href="#ackownledgement">Ackownledgement</a>
                </li>
              
            

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container-fluid mt-5">
      
      <div class="row justify-content-md-center">
        <div class="col-sm-8">
          <!-- about.html -->
      <div class="post">
        <header class="post-header">
          <div class="header-content">
<!--      <p class="desc">AI Research for Generalizable and Interpretable Machine Autonomy</p>-->
            <br>
      <h5>AI Research for Generalizable and Interpretable Machine Autonomy</h5>
    </div>
        </header>


        <!-- Carousel -->
<!--        <div id="myCarousel" class="carousel slide" data-ride="carousel">-->
<!--          <ol class="carousel-indicators">-->
<!--            <li data-target="#myCarousel" data-slide-to="0" class="active">-->
<!--                <i class="fas fa-circle fa-xs"></i>-->
<!--            </li>-->
<!--            <li data-target="#myCarousel" data-slide-to="1">-->
<!--                <i class="fas fa-circle fa-xs"></i>-->
<!--            </li>-->
<!--            <li data-target="#myCarousel" data-slide-to="2">-->
<!--                <i class="fas fa-circle fa-xs"></i>-->
<!--            </li>-->
<!--          </ol>-->
<!--          <div class="carousel-inner"  style="border-radius: 1em; max-width: 61.5%; margin: auto;">-->
<!--            -->
<!--              <div class="carousel-item active">-->
<!--                <img src="/assets/img/multi-agent.png" class="d-block w-100" alt="Slide 1">-->
<!--              </div>-->
<!--            -->
<!--              <div class="carousel-item ">-->
<!--                <img src="/assets/img/realrendering.png" class="d-block w-100" alt="Slide 2">-->
<!--              </div>-->
<!--            -->
<!--              <div class="carousel-item ">-->
<!--                <img src="/assets/img/infinite-scenario.png" class="d-block w-100" alt="Slide 3">-->
<!--              </div>-->
<!--            -->
<!--          </div>-->
<!--          <a class="carousel-control-prev" href="#myCarousel" role="button" data-slide="prev">-->
<!--            <i class="fas fa-chevron-left fa-3x"></i>-->
<!--            <span class="sr-only">Previous</span>-->
<!--          </a>-->
<!--          <a class="carousel-control-next" href="#myCarousel" role="button" data-slide="next">-->
<!--              <i class="fas fa-chevron-right fa-3x"></i>-->
<!--              <span class="sr-only">Next</span>-->
<!--          </a>-->
<!--        </div>-->


        <article>
          

          <div class="clearfix">
            <!-- _pages/publications.md -->
<div class="publications">

<h2 id="papers">Papers</h2>

<!-- To use years as categories, add 
years: [2023,2022,2021]
to header!
-->

<div class="research-section">
<ol class="bibliography">
<li><div class="row align-items-center">
    <div>
        <div class="col-xs-7  col-md-6 col-lg-5 col-xl-4 teaserblock">

            
            
            <abbrbadge class="badge">CVPR</abbrbadge>
            
            

            

            
            <div class="videoplayer">
                <video autoplay="autoplay" muted="" loop="loop" playsinline="" class="z-depth-1">
                    <source src="../assets/teaser/cover_vid2sim.mp4" type="video/mp4"></source>
                </video>
            </div>

            <!--    <img src="../assets/teaser/cover_vid2sim.mp4" class="teaser img-fluid z-depth-1">-->
            

        </div>
    </div>

    <div id="vid2sim" class="col-xs-5 col-md-6 col-lg-7 col-xl-8" style="vertical-align: middle; ">
        
        <div class="title">Vid2Sim: Realistic and Interactive Simulation from Video for Urban Navigation</div>
        <div class="author">
            
            
            
            
            

            
            

            

            
            
            
            
            Ziyang Xie,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhizheng Liu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhenghao Peng,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Wayne Wu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            and Bolei Zhou
            
            
            
            
            
        </div>

        <div class="periodical">

            
            Conference on Computer Vision and Pattern Recognition
            

            
            (<b>CVPR</b>)
            <!--            CVPR-->
            
            
            , 2025
            
        </div>
        

        <div class="links">
            
            <a href="https://metadriverse.github.io/vid2sim" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a>
            
            
            
            <a href="https://arxiv.org/abs/2501.06693" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a>
            
            
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        <!--    -->

        <!-- Hidden bibtex block -->
        <!--    -->
    </div>
</div></li>
<li><div class="row align-items-center">
    <div>
        <div class="col-xs-7  col-md-6 col-lg-5 col-xl-4 teaserblock">

            
            
            <abbrbadge class="badge">NeurIPS</abbrbadge>
            
            

            

            
            <div class="videoplayer">
                <video autoplay="autoplay" muted="" loop="loop" playsinline="" class="z-depth-1">
                    <source src="../assets/teaser/SimGen4x3.mp4" type="video/mp4"></source>
                </video>
            </div>

            <!--    <img src="../assets/teaser/SimGen4x3.mp4" class="teaser img-fluid z-depth-1">-->
            

        </div>
    </div>

    <div id="simgen" class="col-xs-5 col-md-6 col-lg-7 col-xl-8" style="vertical-align: middle; ">
        
        <div class="title">SimGen: Simulator-conditioned Driving Scene Generation</div>
        <div class="author">
            
            
            
            
            

            
            

            

            
            
            
            
            Yunsong Zhou,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Michael Simon,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhenghao Peng,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Sicheng Mo,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Hongzi Zhu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Minyi Guo,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            and Bolei Zhou
            
            
            
            
            
        </div>

        <div class="periodical">

            
            Advances in Neural Information Processing Systems
            

            
            (<b>NeurIPS</b>)
            <!--            NeurIPS-->
            
            
            , 2024
            
        </div>
        

        <div class="links">
            
            <a href="https://metadriverse.github.io/simgen" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a>
            
            
            
            <a href="https://arxiv.org/abs/2406.09386" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a>
            
            
            
            
            
            
            
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        <!--    -->

        <!-- Hidden bibtex block -->
        <!--    -->
    </div>
</div></li>
<li><div class="row align-items-center">
    <div>
        <div class="col-xs-7  col-md-6 col-lg-5 col-xl-4 teaserblock">

            
            
            <abbrbadge class="badge">NeurIPS</abbrbadge>
            
            

            

            
            <div class="videoplayer">
                <video autoplay="autoplay" muted="" loop="loop" playsinline="" class="z-depth-1">
                    <source src="../assets/teaser/cover_ScenarioNet.mp4" type="video/mp4"></source>
                </video>
            </div>

            <!--    <img src="../assets/teaser/cover_ScenarioNet.mp4" class="teaser img-fluid z-depth-1">-->
            

        </div>
    </div>

    <div id="scenarionet" class="col-xs-5 col-md-6 col-lg-7 col-xl-8" style="vertical-align: middle; ">
        
        <div class="title">ScenarioNet: Open-Source Platform for Large-Scale Traffic Scenario Simulation and Modeling</div>
        <div class="author">
            
            
            
            
            

            
            

            

            
            
            
            
            Quanyi Li*,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhenghao Peng*,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Lan Feng*,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhizheng Liu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Chenda Duan,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Wenjie Mo,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            and Bolei Zhou
            
            
            
            
            
        </div>

        <div class="periodical">

            
            Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track
            

            
            (<b>NeurIPS</b>)
            <!--            NeurIPS-->
            
            
            , 2023
            
        </div>
        

        <div class="links">
            
            <a href="https://metadriverse.github.io/scenarionet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a>
            
            
            
            <a href="https://arxiv.org/pdf/2306.12241.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a>
            
            
            
            
            
            
            
            
            <a href="https://github.com/metadriverse/scenarionet" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        <!--    -->

        <!-- Hidden bibtex block -->
        <!--    -->
    </div>
</div></li>
<li><div class="row align-items-center">
    <div>
        <div class="col-xs-7  col-md-6 col-lg-5 col-xl-4 teaserblock">

            
            
            <abbrbadge class="badge">CVPR</abbrbadge>
            
            

            

            
            <div class="videoplayer">
                <video autoplay="autoplay" muted="" loop="loop" playsinline="" class="z-depth-1">
                    <source src="../assets/teaser/v2v4real.png" type="video/mp4"></source>
                </video>
            </div>

            <!--    <img src="../assets/teaser/v2v4real.png" class="teaser img-fluid z-depth-1">-->
            

        </div>
    </div>

    <div id="v2v4real" class="col-xs-5 col-md-6 col-lg-7 col-xl-8" style="vertical-align: middle; ">
        
        <div class="title">V2V4Real: A Real-world Large-scale Dataset for Vehicle-to-vehicle Cooperative Perception</div>
        <div class="author">
            
            
            
            
            

            
            

            

            
            
            
            
            Runsheng Xu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Xin Xia,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Jinlong Li,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Hanzhao Li,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Shuo Zhang,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhengzhong Tu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zonglin Meng,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            and  al.
            
            
            
            
            
        </div>

        <div class="periodical">

            
            Conference on Computer Vision and Pattern Recognition
            

            
            (<b>CVPR</b>)
            <!--            CVPR-->
            
            
            , 2023
            
        </div>
        

        <div class="links">
            
            
            
            <a href="https://arxiv.org/abs/2303.07601" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a>
            
            
            
            
            
            
            
            
            <a href="https://github.com/ucla-mobility/V2V4Real" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        <!--    -->

        <!-- Hidden bibtex block -->
        <!--    -->
    </div>
</div></li>
<li><div class="row align-items-center">
    <div>
        <div class="col-xs-7  col-md-6 col-lg-5 col-xl-4 teaserblock">

            
            
            <abbrbadge class="badge">CoRL</abbrbadge>
            
            

            

            
            <div class="videoplayer">
                <video autoplay="autoplay" muted="" loop="loop" playsinline="" class="z-depth-1">
                    <source src="../assets/teaser/cobevt.gif" type="video/mp4"></source>
                </video>
            </div>

            <!--    <img src="../assets/teaser/cobevt.gif" class="teaser img-fluid z-depth-1">-->
            

        </div>
    </div>

    <div id="cobevt" class="col-xs-5 col-md-6 col-lg-7 col-xl-8" style="vertical-align: middle; ">
        
        <div class="title">CoBEVT: Cooperative Bird’s Eye View Semantic Segmentation with Sparse Transformers</div>
        <div class="author">
            
            
            
            
            

            
            

            

            
            
            
            
            Runsheng Xu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhengzhong Tu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Hao Xiang,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Wei Shao,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Bolei Zhou,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            and Jiaqi Ma
            
            
            
            
            
        </div>

        <div class="periodical">

            
            Conference on Robot Learning
            

            
            (<b>CoRL</b>)
            <!--            CoRL-->
            
            
            , 2023
            
        </div>
        

        <div class="links">
            
            
            
            <a href="https://arxiv.org/abs/2207.02202" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a>
            
            
            
            
            
            
            
            
            <a href="https://github.com/DerrickXuNu/CoBEVT" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        <!--    -->

        <!-- Hidden bibtex block -->
        <!--    -->
    </div>
</div></li>
<li><div class="row align-items-center">
    <div>
        <div class="col-xs-7  col-md-6 col-lg-5 col-xl-4 teaserblock">

            
            
            <abbrbadge class="badge">ECCV</abbrbadge>
            
            

            

            
            <div class="videoplayer">
                <video autoplay="autoplay" muted="" loop="loop" playsinline="" class="z-depth-1">
                    <source src="../assets/teaser/v2v4.mp4" type="video/mp4"></source>
                </video>
            </div>

            <!--    <img src="../assets/teaser/v2v4.mp4" class="teaser img-fluid z-depth-1">-->
            

        </div>
    </div>

    <div id="v2xvit" class="col-xs-5 col-md-6 col-lg-7 col-xl-8" style="vertical-align: middle; ">
        
        <div class="title">V2X-ViT: Vehicle-to-everything Cooperative Perception with Vision Transformer</div>
        <div class="author">
            
            
            
            
            

            
            

            

            
            
            
            
            Runsheng Xu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Hao Xiang,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhengzhong Tu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Xin Xia,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Ming-Hsuan Yang,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            and Jiaqi Ma
            
            
            
            
            
        </div>

        <div class="periodical">

            
            European Conference on Computer Vision
            

            
            (<b>ECCV</b>)
            <!--            ECCV-->
            
            
            , 2022
            
        </div>
        

        <div class="links">
            
            
            
            <a href="https://arxiv.org/abs/2203.10638" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a>
            
            
            
            
            
            
            
            
            <a href="https://github.com/DerrickXuNu/v2x-vit" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        <!--    -->

        <!-- Hidden bibtex block -->
        <!--    -->
    </div>
</div></li>
<li><div class="row align-items-center">
    <div>
        <div class="col-xs-7  col-md-6 col-lg-5 col-xl-4 teaserblock">

            
            
            <abbrbadge class="badge">ICRA</abbrbadge>
            
            

            

            
            <div class="videoplayer">
                <video autoplay="autoplay" muted="" loop="loop" playsinline="" class="z-depth-1">
                    <source src="../assets/teaser/opv2v.gif" type="video/mp4"></source>
                </video>
            </div>

            <!--    <img src="../assets/teaser/opv2v.gif" class="teaser img-fluid z-depth-1">-->
            

        </div>
    </div>

    <div id="opv2v" class="col-xs-5 col-md-6 col-lg-7 col-xl-8" style="vertical-align: middle; ">
        
        <div class="title">OPV2V: An Open Benchmark Dataset and Fusion Pipeline for Perception with Vehicle-to-vehicle Communication</div>
        <div class="author">
            
            
            
            
            

            
            

            

            
            
            
            
            Runsheng Xu,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Hao Xiang,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Xin Xia,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Xu Han,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Jinlong Li,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            and Jiaqi Ma
            
            
            
            
            
        </div>

        <div class="periodical">

            
            International Conference on Robotics and Automation
            

            
            (<b>ICRA</b>)
            <!--            ICRA-->
            
            
            , 2022
            
        </div>
        

        <div class="links">
            
            
            
            <a href="https://arxiv.org/abs/2109.07644" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a>
            
            
            
            
            
            
            
            
            <a href="https://github.com/DerrickXuNu/OpenCOOD" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        <!--    -->

        <!-- Hidden bibtex block -->
        <!--    -->
    </div>
</div></li>
<li><div class="row align-items-center">
    <div>
        <div class="col-xs-7  col-md-6 col-lg-5 col-xl-4 teaserblock">

            
            
            <abbrbadge class="badge">TPAMI</abbrbadge>
            
            

            
            <img src="../assets/teaser/cover_metadrive.png" class="teaser z-depth-1">
            

            

        </div>
    </div>

    <div id="li2021metadrive" class="col-xs-5 col-md-6 col-lg-7 col-xl-8" style="vertical-align: middle; ">
        
        <div class="title">MetaDrive: Composing Diverse Driving Scenarios for Generalizable Reinforcement Learning</div>
        <div class="author">
            
            
            
            
            

            
            

            

            
            
            
            
            Quanyi Li*,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhenghao Peng*,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Lan Feng,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Qihang Zhang,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            Zhenghai Xue,
            
            
            
            
            
            
            
            
            

            
            

            

            
            
            
            
            and Bolei Zhou
            
            
            
            
            
        </div>

        <div class="periodical">

            
            
            

            
            (<b>TPAMI</b>)
            <!--            TPAMI-->
            
            
            , 2021
            
        </div>
        

        <div class="links">
            
            <a href="https://metadriverse.github.io/metadrive/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Webpage</a>
            
            
            
            <a href="https://arxiv.org/pdf/2109.12674" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">PDF</a>
            
            
            
            
            
            
            
            
            <a href="https://github.com/metadriverse/metadrive" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Code</a>
            
            
            <a href="https://www.youtube.com/embed/3ziJPqC_-T4" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="external nofollow noopener">Video</a>
            
            
            
            
            
        </div>

        <!-- Hidden abstract block -->
        <!--    -->

        <!-- Hidden bibtex block -->
        <!--    -->
    </div>
</div></li>
</ol>
</div>

</div>

<!--software-->

<h2 id="software">Software</h2>

<div class="research-section">

  <section style="text-align: center;">
  <h3>MetaDrive</h3>
    <p>AI Research for Generalizable and Interpretable Machine Autonomy</p>

    <p class="nav-links">
      <a href="https://github.com/metadriverse/metadrive" target="_blank" rel="external nofollow noopener">Code</a> |
      <a href="https://metadrive-simulator.readthedocs.io/en/latest/" target="_blank" rel="external nofollow noopener">Documentation</a> |
      <a href="https://www.youtube.com/embed/3ziJPqC_-T4" target="_blank" rel="external nofollow noopener">Demo Video</a> |
      <a href="https://arxiv.org/pdf/2109.12674.pdf" target="_blank" rel="external nofollow noopener">Paper</a>
    </p>
  </section>

  <video style="display:block; width:100%; height:auto;" autoplay="" muted="" loop="" controls="" playsinline="">
    <source src="https://raw.githubusercontent.com/decisionforce/archive/master/MetaDrive/metadrive_teaser.mp4" type="video/mp4"></source>
  </video>

  <br>

  <h3>MetaDrive Simulator</h3>
  <p>To facilitate the research of generalizable reinforcement learning, we develop an open-source, highly efficient and flexible driving simulator MetaDrive, which holds the following key features:</p>
  <ul>
    <li>Modular</li>
    <li>Lightweight</li>
    <li>Customizable</li>
    <li>Realistic</li>
  </ul>
  <p>We construct a variety of RL tasks and baselines in both single-agent and multi-agent settings, including benchmarking generalizability across unseen scenes, safe exploration, and modeling multi-agent behaviors.</p>
  <p>Empowered by <strong><em><a href="../scenarionet">ScenarioNet</a></em></strong>, all features of MetaDrive can be applied to the virtual environments reconstructed from the open-source dataset, such as Waymo Open Dataset, nuPlan, and L5.</p>

  <br>
  
  <h3>OpenCDA</h3>
  <img style="display:block; width:100%; height:auto;" src="/assets/img/DriveX/openCDA.png" alt="OpenCDA Logo">
  <img style="display:block; width:100%; height:auto;" src="/assets/img/DriveX/openCDA2.gif" alt="OpenCDA Demo GIF">
  <p><strong>OpenCDA:</strong> an open co-simulation-based research/engineering framework integrated with prototype cooperative driving automation pipelines and automated driving components.</p>
  <p>Xu, Runsheng, et al. “OpenCDA: an open cooperative driving automation framework integrated with co-simulation.” 2021 IEEE International Intelligent Transportation Systems Conference (ITSC). IEEE, 2021.</p>
  <p><a href="https://github.com/ucla-mobility/OpenCDA" rel="external nofollow noopener" target="_blank">https://github.com/ucla-mobility/OpenCDA</a></p>
</div>

<!--Datasets-->

<h2 id="datasets">Datasets</h2>

<div class="research-section">
    <h3 style="text-align: left">DIVA Dataset</h3>

    <div class="white-background">
        <img src="/assets/img/DriveX/DIVA-sim.png">
    </div>
</div>

<div class="research-section">
    <h3 style="text-align: left">Vid2Sim Dataset</h3>

    <div class="white-background">
        <img src="/assets/img/DriveX/Vid2sim.png">
    </div>
</div>

<div class="research-section">
    <h3 style="text-align: left">CityWalker Dataset</h3>

    <div class="white-background">
        <img src="/assets/img/DriveX/CityWalker.png">
    </div>
</div>

<div class="research-section">
    <h3 style="text-align: left">V2X-Real Dataset</h3>
    <ul style="list-style-type: none; padding-left: 0;">
        V2X-Real: the first large-scale real-world dataset for Vehicle-to-Everything (V2X) cooperative perception.

        Xiang, Hao, et al. “V2X-Real: a large-scale dataset for vehicle-to-everything cooperative perception." European Conference on Computer Vision. Cham: Springer Nature Switzerland, 2024.

        https://mobility-lab.seas.ucla.edu/v2x-real/
        https://github.com/ucla-mobility/V2X-Real

    </ul>

    <div class="white-background">
        <img src="/assets/img/DriveX/V2X.png">
    </div>
</div>

<!--Outreach-->
<h2 id="outreach">Outreach</h2>

<div class="research-section">
    <h3 style="text-align: left">Workshops &amp; Panels &amp; Webinars</h3>
    <ul style="padding-left: 10;">
        <li>Workshop at CVPR 2024</li>
        <li>Workshop with UCB 2025</li>
    </ul>
</div>

<div class="research-section">
    <h3 style="text-align: left">Online Educational Resources</h3>
    <ul style="padding-left: 10;">
        <li>Colab and Tutorial of MetaDrive</li>
    </ul>
</div>

<!--Outreach-->
<h2 id="acknowledgement">Acknowledgement</h2>

<div class="row justify-content-center align-items-center">
    <div class="col-xs-3 col-md-3 col-img">
        <img src="/assets/img/DriveX/nsf.png" alt="NSF" class="logo">
    </div>
    <div class="col-xs-4 col-md-4 col-img">
        The workshop is supported by <b>NSF CCRI grants 2235012 and 2235013</b>.
    </div> 
</div>

<style>
.custom-heading {
  font-size: 1.5em;
  font-weight: bold;
  margin-bottom: 10px; /* Adjust this value as needed */
}
.white-background {
    background-color: white;
    display: block; /* Changed from inline-block if you want it to take the full width available */
    width: 100%; /* Ensures it takes the full width of its parent container */
    overflow: hidden; /* This will prevent any overflow outside this div */
    padding: 10px;
}
.white-background img {
    width: 100%; /* Makes the image responsive */
    height: auto; /* Keeps the image's aspect ratio intact */
}
.logo {
    display: inline; /* Changed from inline-block if you want it to take the full width available */
    width: 100%; /* Ensures it takes the full width of its parent container */
    overflow: hidden; /* This will prevent any overflow outside this div */
    padding: 10px;
}
.logo img {
    width: 100%; /* Makes the image responsive */
    height: auto; /* Keeps the image's aspect ratio intact */
}
.video-grid {
    display: grid;
    grid-template-columns: 1fr 1fr; /* Creates two columns */
    grid-gap: 20px; /* Space between videos */
}
.video iframe {
    width: 100%; /* Ensures iframe takes the full width of the container */
    height: 250px; /* Fixed height for all videos */
}

@media (max-width: 600px) {
    .video-grid {
        grid-template-columns: 1fr; /* Stacks videos into a single column on small screens */
    }
}
.gif img {
    width: 100%; /* Ensures the GIFs fill the cells */
    height: auto; /* Maintains the aspect ratio */
}
</style>


          </div>
            <!-- Add this to your main page where you want the posts to appear -->
<!--            -->
<!--            <div class="category-list">-->
<!--              <h2 class="category-title"><a href="/blog/" style="color: inherit;">Latest News</a></h2>-->
<!--              <ul class="category-list-ul p-0 m-0">-->
<!--                -->
<!--                  <li class="category-item">-->
<!--                    <i class="fas fa-tag fa-sm"></i> <a href="/blog/category/metadriverse-updates">Metadriverse-Updates</a>-->
<!--                  </li>-->
<!--                  -->
<!--                -->
<!--              </ul>-->
<!--            </div>-->
<!--            -->
<!--            <div class="row">-->
<!--            -->

<!--            -->
<!--            -->
<!--            -->
<!--            -->

<!--            <div class="col-lg-6">-->
<!--              <ul class="post-list">-->
<!--                <li>-->
<!--                  <div class="row">-->
<!--                    &lt;!&ndash; Content area &ndash;&gt;-->
<!--                    -->
<!--                    <div class="col-sm-12">-->
<!--                    -->
<!--                      <h4 style="font-size: 1.5em;">-->
<!--                        <a class="post-title" href="//metadriverse-updates/2023/06/17/Metadriverse-Updates.html">Metadriverse's New Official Website is On!</a>-->
<!--                      </h4>-->
<!--                      <p>We are thrilled that our Metadriverse's New Official Website is On!</p>-->
<!--                      <p class="post-meta">-->
<!--                        1 min read &nbsp; &middot; &nbsp;-->
<!--                        June 17, 2023-->
<!---->
<!--                      </p>-->
<!--                      <p class="post-tags">-->
<!--                        <a href="//blog/2023">-->
<!--                          <i class="fas fa-calendar fa-sm"></i> 2023 </a>-->
<!--            -->
<!--                          -->
<!--                          &nbsp; &middot; &nbsp;-->
<!--                            -->
<!--                            <a href="//blog/tag/metadriverse">-->
<!--                              <i class="fas fa-hashtag fa-sm"></i> Metadriverse</a> &nbsp;-->
<!--                              -->
<!--                            <a href="//blog/tag/updates">-->
<!--                              <i class="fas fa-hashtag fa-sm"></i> Updates</a> &nbsp;-->
<!--                              -->
<!--                          -->
<!--            -->
<!--                          -->
<!--                          &nbsp; &middot; &nbsp;-->
<!--                            -->
<!--                            <a href="//blog/category/metadriverse-updates">-->
<!--                              <i class="fas fa-tag fa-sm"></i> Metadriverse-Updates</a> &nbsp;-->
<!--                              -->
<!--                          -->
<!--                      </p>-->
<!--                    </div>-->
<!--                    &lt;!&ndash; Image area &ndash;&gt;-->
<!---->
<!--                  </div>-->
<!--                </li>-->
<!--              </ul>-->
<!--            </div>-->
<!---->
<!--          </div>-->


          <!-- <h2 class="category-title">Features</h2> -->
          <div class="features"></div>








          <!-- Social -->
        </article>

</div>

        </div>
      </div>
      
    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2025   DriveX. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
